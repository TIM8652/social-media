import schedule
import time
import psycopg2
from psycopg2.extras import RealDictCursor
from datetime import datetime
from cpostscrape import scrape_posts, save_posts_to_db, get_db_connection
from translate import translate_competitor

# æ•°æ®åº“é…ç½®
DB_CONFIG = {
    "host": "localhost",
    "port": 5432,
    "database": "social_media",
    "user": "postgres",
    "password": "1234qwer"
}

def get_all_competitors():
    """è·å–æ‰€æœ‰ç«å“ç”¨æˆ·å"""
    conn = get_db_connection()
    cursor = conn.cursor()
    
    cursor.execute('SELECT id, username FROM competitor ORDER BY id')
    competitors = cursor.fetchall()
    
    cursor.close()
    conn.close()
    
    return competitors

def check_post_exists(post_id):
    """æ£€æŸ¥å¸–å­æ˜¯å¦å·²å­˜åœ¨"""
    conn = get_db_connection()
    cursor = conn.cursor()
    
    cursor.execute('SELECT id FROM post_data WHERE post_id = %s', (post_id,))
    result = cursor.fetchone()
    
    cursor.close()
    conn.close()
    
    return result is not None

def incremental_scrape_competitor(username):
    """
    å¢é‡æŠ“å–ç«å“æ•°æ®
    
    é€»è¾‘ï¼š
    1. ç¬¬ä¸€æ¬¡æŠ“å– 1 æ¡ posts
    2. æ£€æŸ¥ post_id æ˜¯å¦å·²å­˜åœ¨
    3. å¦‚æœå·²å­˜åœ¨ï¼šè¦†ç›–å¸–å­å¹¶åœæ­¢
    4. å¦‚æœä¸å­˜åœ¨ï¼šä¿å­˜å¸–å­ï¼Œå†æŠ“å– 1 æ¡ï¼Œé‡å¤æ­¥éª¤ 2-3
    5. ç›´åˆ°æ‰¾åˆ°å·²å­˜åœ¨çš„å¸–å­ä¸ºæ­¢
    
    Args:
        username: ç«å“ç”¨æˆ·å
    
    Returns:
        dict: æŠ“å–ç»“æœç»Ÿè®¡
    """
    print(f"\n{'='*60}")
    print(f"å¼€å§‹å¢é‡æŠ“å–ç«å“: {username}")
    print(f"æ—¶é—´: {datetime.now().strftime('%Y-%m-%d %H:%M:%S')}")
    print(f"{'='*60}\n")
    
    total_new_posts = 0
    total_updated_posts = 0
    batch_size = 1  # æ¯æ¬¡æŠ“å– 1 æ¡
    max_batches = 50  # æœ€å¤šæŠ“å– 50 æ¬¡ï¼ˆé˜²æ­¢æ— é™å¾ªç¯ï¼‰
    
    for batch_num in range(1, max_batches + 1):
        print(f"\nğŸ“¥ ç¬¬ {batch_num} è½®æŠ“å–...")
        
        # æŠ“å– 1 æ¡ posts ç±»å‹çš„å¸–å­
        posts = scrape_posts(username, batch_size, scrape_type="posts")
        
        if not posts:
            print(f"  âš ï¸  æœªè·å–åˆ°å¸–å­ï¼Œåœæ­¢æŠ“å–")
            break
        
        # æ£€æŸ¥è¿™æ¡å¸–å­æ˜¯å¦å·²å­˜åœ¨
        post = posts[0]
        post_id = post.get('id')
        exists = check_post_exists(post_id)
        
        if exists:
            print(f"  âœ… å‘ç°å·²å­˜åœ¨çš„å¸–å­: {post_id}")
            print(f"  ğŸ”„ è¦†ç›–æ›´æ–°å¹¶åœæ­¢æŠ“å–...")
            
            # ä¿å­˜ï¼ˆä¼šè‡ªåŠ¨è¦†ç›–ï¼‰
            saved = save_posts_to_db(posts, username)
            if saved > 0:
                total_updated_posts += saved
            
            print(f"  âœ… å·²è¦†ç›–å¸–å­ï¼Œåœæ­¢æŠ“å–")
            break
        else:
            print(f"  ğŸ†• å‘ç°æ–°å¸–å­: {post_id}")
            print(f"  ğŸ’¾ ä¿å­˜å¹¶ç»§ç»­æŠ“å–...")
            
            # ä¿å­˜æ–°å¸–å­
            saved = save_posts_to_db(posts, username)
            if saved > 0:
                total_new_posts += saved
            
            # ç»§ç»­ä¸‹ä¸€è½®æŠ“å–
            continue
    
    print(f"\n{'='*60}")
    print(f"æŠ“å–å®Œæˆ: {username}")
    print(f"æ–°å¢å¸–å­: {total_new_posts} æ¡")
    print(f"æ›´æ–°å¸–å­: {total_updated_posts} æ¡")
    print(f"{'='*60}\n")
    
    return {
        "username": username,
        "new_posts": total_new_posts,
        "updated_posts": total_updated_posts,
        "total": total_new_posts + total_updated_posts
    }

def daily_competitor_scrape():
    """æ¯æ—¥å®šæ—¶æŠ“å–æ‰€æœ‰ç«å“"""
    print(f"\nğŸ•’ å¼€å§‹æ¯æ—¥ç«å“æŠ“å–ä»»åŠ¡")
    print(f"æ—¶é—´: {datetime.now().strftime('%Y-%m-%d %H:%M:%S')}")
    print(f"{'='*80}\n")
    
    try:
        # è·å–æ‰€æœ‰ç«å“
        competitors = get_all_competitors()
        
        if not competitors:
            print("âš ï¸  æ²¡æœ‰æ‰¾åˆ°ç«å“ï¼Œè·³è¿‡æŠ“å–")
            return
        
        print(f"ğŸ“Š å…±æ‰¾åˆ° {len(competitors)} ä¸ªç«å“")
        print(f"{'='*80}\n")
        
        results = []
        
        # é€ä¸ªæŠ“å–
        for idx, competitor in enumerate(competitors, 1):
            competitor_id = competitor['id']
            username = competitor['username']
            
            print(f"\n[{idx}/{len(competitors)}] å¤„ç†ç«å“: {username} (ID: {competitor_id})")
            
            try:
                result = incremental_scrape_competitor(username)
                results.append(result)
                
                # ä¼‘æ¯ 5 ç§’ï¼Œé¿å…è¯·æ±‚è¿‡å¿«
                if idx < len(competitors):
                    print(f"â³ ç­‰å¾… 5 ç§’...")
                    time.sleep(5)
                    
            except Exception as e:
                print(f"âŒ æŠ“å–å¤±è´¥: {username}, é”™è¯¯: {e}")
                import traceback
                traceback.print_exc()
                continue
        
        # ç»Ÿè®¡æ€»ç»“
        total_new = sum(r['new_posts'] for r in results)
        total_updated = sum(r['updated_posts'] for r in results)
        
        print(f"\n{'='*80}")
        print(f"âœ… æ¯æ—¥æŠ“å–ä»»åŠ¡å®Œæˆï¼")
        print(f"{'='*80}")
        print(f"å¤„ç†ç«å“æ•°: {len(results)}/{len(competitors)}")
        print(f"æ–°å¢å¸–å­: {total_new} æ¡")
        print(f"æ›´æ–°å¸–å­: {total_updated} æ¡")
        print(f"æ€»è®¡: {total_new + total_updated} æ¡")
        print(f"{'='*80}\n")
        
    except Exception as e:
        print(f"âŒ æ¯æ—¥æŠ“å–ä»»åŠ¡å¤±è´¥: {e}")
        import traceback
        traceback.print_exc()

def start_scheduler():
    """å¯åŠ¨å®šæ—¶ä»»åŠ¡è°ƒåº¦å™¨"""
    print("ğŸš€ ç«å“è‡ªåŠ¨æŠ“å–è°ƒåº¦å™¨å·²å¯åŠ¨")
    print(f"â° æ¯å¤©åŒ—äº¬æ—¶é—´ 16:30 æ‰§è¡ŒæŠ“å–ä»»åŠ¡")
    print(f"å½“å‰æ—¶é—´: {datetime.now().strftime('%Y-%m-%d %H:%M:%S')}")
    print(f"{'='*80}\n")
    
    # è®¾ç½®æ¯å¤© 16:30 æ‰§è¡Œ
    schedule.every().day.at("16:30").do(daily_competitor_scrape)
    
    # å¯é€‰ï¼šç«‹å³æ‰§è¡Œä¸€æ¬¡ï¼ˆç”¨äºæµ‹è¯•ï¼‰
    # print("ğŸ§ª æµ‹è¯•æ¨¡å¼ï¼šç«‹å³æ‰§è¡Œä¸€æ¬¡æŠ“å–ä»»åŠ¡\n")
    # daily_competitor_scrape()
    
    # æŒç»­è¿è¡Œ
    while True:
        schedule.run_pending()
        time.sleep(60)  # æ¯åˆ†é’Ÿæ£€æŸ¥ä¸€æ¬¡

if __name__ == "__main__":
    # ç›´æ¥è¿è¡Œæ—¶å¯åŠ¨è°ƒåº¦å™¨
    start_scheduler()

