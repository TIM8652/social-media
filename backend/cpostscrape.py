import os
import json
import base64
import requests
from datetime import datetime
from apify_client import ApifyClient
from dotenv import load_dotenv
from translate import translate_competitor, translate_post_by_id
from database import get_db_connection

load_dotenv()

# Apifyå®¢æˆ·ç«¯
from apiconfig import get_api_key

def get_apify_client():
    token = get_api_key("APIFY_API_TOKEN") or os.getenv("APIFY_API_TOKEN", "")
    return ApifyClient(token)

client = get_apify_client()

def check_competitor_exists(username):
    """æ£€æŸ¥ç«å“æ˜¯å¦å·²å­˜åœ¨"""
    conn = get_db_connection()
    cursor = conn.cursor()
    cursor.execute('SELECT id FROM competitor WHERE username = %s', (username,))
    result = cursor.fetchone()
    cursor.close()
    conn.close()
    return result is not None

def download_image_to_base64(url):
    """ä¸‹è½½å›¾ç‰‡å¹¶è½¬æ¢ä¸ºBase64"""
    try:
        response = requests.get(url, timeout=10)
        if response.status_code == 200:
            return base64.b64encode(response.content).decode('utf-8')
    except Exception as e:
        print(f"ä¸‹è½½å›¾ç‰‡å¤±è´¥: {url}, é”™è¯¯: {e}")
    return None

def download_video_to_base64(url):
    """ä¸‹è½½è§†é¢‘å¹¶è½¬æ¢ä¸ºBase64ï¼ˆå¸¦è¶…æ—¶å’Œå¤§å°é™åˆ¶ï¼‰"""
    try:
        print(f"æ­£åœ¨ä¸‹è½½è§†é¢‘: {url[:80]}...")
        # è®¾ç½®è¾ƒé•¿çš„è¶…æ—¶æ—¶é—´ï¼ˆè§†é¢‘æ–‡ä»¶è¾ƒå¤§ï¼‰
        response = requests.get(url, timeout=120, stream=True)
        if response.status_code == 200:
            # é™åˆ¶è§†é¢‘å¤§å°ï¼ˆä¾‹å¦‚æœ€å¤§100MBï¼‰
            max_size = 100 * 1024 * 1024  # 100MB
            video_data = b""
            downloaded_size = 0
            
            for chunk in response.iter_content(chunk_size=8192):
                video_data += chunk
                downloaded_size += len(chunk)
                
                # æ˜¾ç¤ºä¸‹è½½è¿›åº¦
                if downloaded_size % (1024 * 1024) == 0:  # æ¯1MBæ˜¾ç¤ºä¸€æ¬¡
                    print(f"  å·²ä¸‹è½½: {downloaded_size / 1024 / 1024:.1f}MB")
                
                if downloaded_size > max_size:
                    print(f"  âš ï¸ è§†é¢‘è¿‡å¤§(>{max_size/1024/1024}MB)ï¼Œè·³è¿‡: {url[:80]}")
                    return None
            
            print(f"  âœ… è§†é¢‘ä¸‹è½½å®Œæˆ: {downloaded_size / 1024 / 1024:.2f}MB")
            return base64.b64encode(video_data).decode('utf-8')
    except Exception as e:
        print(f"  âŒ ä¸‹è½½è§†é¢‘å¤±è´¥: {url[:80]}, é”™è¯¯: {e}")
    return None

def scrape_details(username):
    """æŠ“å–è´¦å·è¯¦æƒ…æ•°æ®"""
    print(f"æ­£åœ¨æŠ“å–è´¦å·è¯¦æƒ…: {username}")
    
    run_input = {
        "directUrls": [f"https://www.instagram.com/{username}/"],
        "resultsType": "details",
        "resultsLimit": 1,
        "searchType": "hashtag",
        "searchLimit": 1,
        "addParentData": False,
    }
    
    try:
        run = client.actor("RB9HEZitC8hIUXAha").call(run_input=run_input)
        results = list(client.dataset(run["defaultDatasetId"]).iterate_items())
        
        if results:
            return results[0]
        return None
    except Exception as e:
        print(f"æŠ“å–è¯¦æƒ…å¤±è´¥: {e}")
        return None

def save_competitor_to_db(data):
    """ä¿å­˜ç«å“æ•°æ®åˆ°æ•°æ®åº“"""
    conn = get_db_connection()
    cursor = conn.cursor()
    
    # ä¸‹è½½å¤´åƒ
    profile_pic_base64 = None
    if data.get('profilePicUrl'):
        profile_pic_base64 = download_image_to_base64(data['profilePicUrl'])
    
    # å‡†å¤‡å¤–éƒ¨é“¾æ¥JSON
    external_urls_json = json.dumps(data.get('externalUrls', []))
    
    cursor.execute('''
        INSERT INTO competitor (
            input_url, instagram_id, username, url, full_name, biography,
            profile_pic_url, profile_pic_base64,
            external_urls, external_url, external_url_shimmed,
            followers_count, follows_count,
            posts_count, has_channel, highlight_reel_count
        ) VALUES (%s, %s, %s, %s, %s, %s, %s, %s, %s, %s, %s, %s, %s, %s, %s, %s)
        RETURNING id
    ''', (
        data.get('inputUrl'),
        data.get('id'),
        data.get('username'),
        data.get('url'),
        data.get('fullName'),
        data.get('biography'),
        data.get('profilePicUrl'),
        profile_pic_base64,
        external_urls_json,
        data.get('externalUrl'),
        data.get('externalUrlShimmed'),
        data.get('followersCount', 0),
        data.get('followsCount', 0),
        data.get('postsCount', 0),
        data.get('hasChannel', False),
        data.get('highlightReelCount', 0)
    ))
    
    competitor_id = cursor.fetchone()['id']
    conn.commit()
    cursor.close()
    conn.close()
    
    print(f"âœ… ç«å“æ•°æ®å·²ä¿å­˜ï¼ŒID: {competitor_id}")
    return competitor_id

def scrape_posts(username, count, scrape_type="both"):
    """
    æŠ“å–å¸–å­æ•°æ®
    
    Args:
        username: ç”¨æˆ·å
        count: æŠ“å–æ•°é‡
        scrape_type: æŠ“å–ç±»å‹ "posts"(å›¾æ–‡) / "stories"(è§†é¢‘) / "both"(ä¸¤è€…)
    
    Returns:
        list: å¸–å­æ•°æ®åˆ—è¡¨
    """
    print(f"æ­£åœ¨æŠ“å–å¸–å­: {username}, æ•°é‡: {count}, ç±»å‹: {scrape_type}")
    
    all_posts = []
    
    # æ ¹æ®ç±»å‹æŠ“å–
    if scrape_type in ["posts", "both"]:
    # æŠ“å–å›¾æ–‡å¸–å­
        print(f"ğŸ“ æŠ“å– {count} æ¡å›¾æ–‡å¸–å­...")
    posts_input = {
        "directUrls": [f"https://www.instagram.com/{username}/"],
        "resultsType": "posts",
        "resultsLimit": count,
        "searchType": "hashtag",
        "searchLimit": 1,
        "addParentData": False,
    }
    
    try:
        run = client.actor("RB9HEZitC8hIUXAha").call(run_input=posts_input)
        posts = list(client.dataset(run["defaultDatasetId"]).iterate_items())
        all_posts.extend(posts)
        print(f"âœ… è·å–åˆ° {len(posts)} æ¡å›¾æ–‡å¸–å­")
    except Exception as e:
        print(f"âŒ æŠ“å–å›¾æ–‡å¸–å­å¤±è´¥: {e}")
    
    if scrape_type in ["stories", "both"]:
    # æŠ“å–è§†é¢‘å¸–å­
        print(f"ğŸ¥ æŠ“å– {count} æ¡è§†é¢‘å¸–å­...")
    stories_input = {
        "directUrls": [f"https://www.instagram.com/{username}/"],
        "resultsType": "stories",
        "resultsLimit": count,
        "searchType": "hashtag",
        "searchLimit": 1,
        "addParentData": False,
    }
    
    try:
        run = client.actor("RB9HEZitC8hIUXAha").call(run_input=stories_input)
        stories = list(client.dataset(run["defaultDatasetId"]).iterate_items())
        all_posts.extend(stories)
        print(f"âœ… è·å–åˆ° {len(stories)} æ¡è§†é¢‘å¸–å­")
    except Exception as e:
        print(f"âŒ æŠ“å–è§†é¢‘å¸–å­å¤±è´¥: {e}")
    
    return all_posts

def save_posts_to_db(posts, username):
    """ä¿å­˜å¸–å­æ•°æ®åˆ°æ•°æ®åº“"""
    conn = get_db_connection()
    cursor = conn.cursor()
    
    # è·å–ç«å“ID
    cursor.execute('SELECT id FROM competitor WHERE username = %s', (username,))
    competitor_result = cursor.fetchone()
    if not competitor_result:
        print(f"âŒ æœªæ‰¾åˆ°ç«å“: {username}")
        cursor.close()
        conn.close()
        return 0
    
    competitor_id = competitor_result['id']
    print(f"âœ… æ‰¾åˆ°ç«å“ID: {competitor_id}")
    
    saved_count = 0
    inserted_ids = []
    for post in posts:
        try:
            post_type = post.get('type')  # åŸå§‹ç±»å‹ï¼šImage, Video, Sidecar
            
            # åˆå§‹åŒ–æ‰€æœ‰åª’ä½“ç›¸å…³å˜é‡
            display_url_base64 = None
            images_base64 = []
            video_url_base64 = None
            videos = []
            videos_base64 = []
            child_posts_order = []
            video_view_count = 0  # è§†é¢‘è§‚çœ‹æ•°
            video_play_count = 0  # è§†é¢‘æ’­æ”¾æ•°
            
            # ä¸‹è½½å°é¢å›¾ï¼ˆdisplayUrlï¼‰
            if post.get('displayUrl'):
                display_url_base64 = download_image_to_base64(post['displayUrl'])
            
            # å¤„ç† Sidecar ç±»å‹ï¼ˆå¤šå›¾/æ··åˆç±»å‹ï¼‰
            if post_type == "Sidecar":
                child_posts = post.get('childPosts', [])
                has_video = False
                
                print(f"  å¤„ç† Sidecar å¸–å­ï¼ŒåŒ…å« {len(child_posts)} ä¸ªå­å¸–å­")
                
                for idx, child in enumerate(child_posts):
                    child_type = child.get('type')
                    print(f"    å­å¸–å­ {idx + 1}/{len(child_posts)}: ç±»å‹ = {child_type}")
                    
                    if child_type == "Video":
                        has_video = True
                        video_url = child.get('videoUrl')
                        if video_url:
                            videos.append(video_url)
                            # ä¸‹è½½è§†é¢‘è½¬Base64
                            video_base64 = download_video_to_base64(video_url)
                            if video_base64:
                                videos_base64.append(video_base64)
                            else:
                                videos_base64.append(None)  # ä¸‹è½½å¤±è´¥ï¼Œå ä½
                            
                            # è®°å½•é¡ºåº
                            child_posts_order.append({
                                "index": idx,
                                "type": "Video",
                                "ref": len(videos) - 1,
                                "short_code": child.get('shortCode'),
                                "video_view_count": child.get('videoViewCount'),
                                "video_duration": child.get('videoDuration')
                            })
                    
                    elif child_type == "Image":
                        img_url = child.get('displayUrl')
                        if img_url:
                            img_base64 = download_image_to_base64(img_url)
                            if img_base64:
                                images_base64.append(img_base64)
                            else:
                                images_base64.append(None)  # ä¸‹è½½å¤±è´¥ï¼Œå ä½
                            
                            # è®°å½•é¡ºåº
                            child_posts_order.append({
                                "index": idx,
                                "type": "Image",
                                "ref": len(images_base64) - 1,
                                "short_code": child.get('shortCode')
                            })
                
                # å¦‚æœåŒ…å«è§†é¢‘ï¼Œä¿®æ”¹post_typeä¸º Sidecar_video
                if has_video:
                    post_type = "Sidecar_video"
                    print(f"  âœ… æ£€æµ‹åˆ°æ··åˆç±»å‹ï¼Œpost_type æ›´æ”¹ä¸º: Sidecar_video")
            
            # å¤„ç†çº¯ Video ç±»å‹ï¼ˆå•è§†é¢‘ï¼‰
            elif post_type == "Video":
                video_url = post.get('videoUrl')
                if video_url:
                    video_url_base64 = download_video_to_base64(video_url)
                # è·å–è§†é¢‘è§‚çœ‹æ•°å’Œæ’­æ”¾æ•°
                video_view_count = post.get('videoViewCount', 0)
                video_play_count = post.get('videoPlayCount', 0)
            
            # å¤„ç†çº¯ Image ç±»å‹ï¼ˆä¸éœ€è¦é¢å¤–å¤„ç†ï¼Œåªæœ‰å°é¢å›¾ï¼‰
            # displayUrl å·²ç»åœ¨ä¸Šé¢å¤„ç†äº†
            
            # å¤„ç†è¯„è®ºæ•°æ®
            latest_comments = post.get('latestComments', [])
            # ä¼˜å…ˆä½¿ç”¨æŠ“å–çš„ firstComment å­—æ®µï¼Œå…¶æ¬¡å›é€€åˆ° latestComments çš„ç¬¬ä¸€æ¡
            first_comment_text = post.get('firstComment') or None
            try:
                if not first_comment_text and isinstance(latest_comments, list) and latest_comments:
                    first = latest_comments[0]
                    if isinstance(first, dict):
                        first_comment_text = first.get('text')
                    elif isinstance(first, str):
                        first_comment_text = first
            except Exception:
                first_comment_text = None

            cursor.execute('''
                INSERT INTO post_data (
                    post_id, post_type, short_code, url, input_url,
                    caption, alt,
                    hashtags, mentions,
                    comments_count, likes_count, is_comments_disabled,
                    latest_comments, first_comment,
                    dimensions_height, dimensions_width,
                    display_url, display_url_base64,
                    video_url, video_url_base64, video_duration,
                    video_view_count, video_play_count,
                    images, images_base64, child_posts,
                    videos, videos_base64, child_posts_order,
                    owner_id, owner_username, owner_full_name,
                    timestamp, is_pinned, is_sponsored, product_type,
                    competitor_id
                ) VALUES (
                    %s, %s, %s, %s, %s, %s, %s, %s, %s, %s, %s, %s, %s, %s,
                    %s, %s, %s, %s, %s, %s, %s, %s, %s, %s, %s, %s, %s, %s, %s,
                    %s, %s, %s, %s, %s, %s, %s, %s
                )
                ON CONFLICT (post_id) DO UPDATE SET
                    post_type = EXCLUDED.post_type,
                    short_code = EXCLUDED.short_code,
                    url = EXCLUDED.url,
                    input_url = EXCLUDED.input_url,
                    caption = EXCLUDED.caption,
                    alt = EXCLUDED.alt,
                    hashtags = EXCLUDED.hashtags,
                    mentions = EXCLUDED.mentions,
                    comments_count = EXCLUDED.comments_count,
                    likes_count = EXCLUDED.likes_count,
                    is_comments_disabled = EXCLUDED.is_comments_disabled,
                    latest_comments = EXCLUDED.latest_comments,
                    first_comment = EXCLUDED.first_comment,
                    dimensions_height = EXCLUDED.dimensions_height,
                    dimensions_width = EXCLUDED.dimensions_width,
                    display_url = EXCLUDED.display_url,
                    display_url_base64 = EXCLUDED.display_url_base64,
                    video_url = EXCLUDED.video_url,
                    video_url_base64 = EXCLUDED.video_url_base64,
                    video_duration = EXCLUDED.video_duration,
                    video_view_count = EXCLUDED.video_view_count,
                    video_play_count = EXCLUDED.video_play_count,
                    images = EXCLUDED.images,
                    images_base64 = EXCLUDED.images_base64,
                    child_posts = EXCLUDED.child_posts,
                    videos = EXCLUDED.videos,
                    videos_base64 = EXCLUDED.videos_base64,
                    child_posts_order = EXCLUDED.child_posts_order,
                    owner_id = EXCLUDED.owner_id,
                    owner_username = EXCLUDED.owner_username,
                    owner_full_name = EXCLUDED.owner_full_name,
                    timestamp = EXCLUDED.timestamp,
                    is_pinned = EXCLUDED.is_pinned,
                    is_sponsored = EXCLUDED.is_sponsored,
                    product_type = EXCLUDED.product_type,
                    competitor_id = EXCLUDED.competitor_id,
                    updated_at = NOW()
                RETURNING id
            ''', (
                post.get('id'),
                post_type,  # å¯èƒ½æ˜¯ "Sidecar_video"
                post.get('shortCode'),
                post.get('url'),
                post.get('inputUrl'),
                post.get('caption'),
                post.get('alt'),
                json.dumps(post.get('hashtags', [])),
                json.dumps(post.get('mentions', [])),
                post.get('commentsCount', 0),
                post.get('likesCount', 0),
                post.get('isCommentsDisabled', False),
                json.dumps(latest_comments),
                first_comment_text,
                post.get('dimensionsHeight'),
                post.get('dimensionsWidth'),
                post.get('displayUrl'),
                display_url_base64,
                post.get('videoUrl'),
                video_url_base64,
                post.get('videoDuration'),
                video_view_count,
                video_play_count,
                json.dumps(post.get('images', [])),
                json.dumps(images_base64) if images_base64 else None,
                json.dumps(post.get('childPosts', [])),
                json.dumps(videos) if videos else None,
                json.dumps(videos_base64) if videos_base64 else None,
                json.dumps(child_posts_order) if child_posts_order else None,
                post.get('ownerId'),
                username,
                post.get('ownerFullName'),
                post.get('timestamp'),
                post.get('isPinned', False),
                post.get('isSponsored', False),
                post.get('productType'),
                competitor_id
            ))
            
            row = cursor.fetchone()
            if row:
                saved_count += 1
                inserted_ids.append(row['id'])
                
        except Exception as e:
            print(f"ä¿å­˜å¸–å­å¤±è´¥ {post.get('id')}: {e}")
            continue
    
    conn.commit()
    cursor.close()
    conn.close()
    
    # å…¥åº“åå¼ºåˆ¶ç¿»è¯‘æ‰€æœ‰ _zh å­—æ®µ
    for db_id in inserted_ids:
        try:
            translate_post_by_id(db_id)
        except Exception as e:
            print(f"ç¿»è¯‘å¸–å­å¤±è´¥ id={db_id}: {e}")
    
    print(f"âœ… æˆåŠŸä¿å­˜ {saved_count} æ¡å¸–å­åˆ°æ•°æ®åº“")
    return saved_count

def scrape_competitor_data(username, post_count, scrape_type="both"):
    """
    ä¸»å‡½æ•°ï¼šæŠ“å–ç«å“æ•°æ®
    
    Args:
        username: ç”¨æˆ·å
        post_count: å¸–å­æ•°é‡
        scrape_type: æŠ“å–ç±»å‹ "posts"(å›¾æ–‡) / "stories"(è§†é¢‘) / "both"(ä¸¤è€…)
    
    Returns:
        dict: æŠ“å–ç»“æœ
    """
    print(f"\n{'='*60}")
    print(f"å¼€å§‹æŠ“å–ç«å“æ•°æ®")
    print(f"ç”¨æˆ·å: {username}")
    print(f"å¸–å­æ•°é‡: {post_count}")
    print(f"æŠ“å–ç±»å‹: {scrape_type}")
    print(f"{'='*60}\n")
    
    # æ£€æŸ¥ç«å“æ˜¯å¦å­˜åœ¨
    exists = check_competitor_exists(username)
    
    if not exists:
        print("ç«å“ä¸å­˜åœ¨ï¼Œå¼€å§‹æŠ“å–è¯¦æƒ…...")
        # æŠ“å–è¯¦æƒ…
        details = scrape_details(username)
        if details:
            # ä¿å­˜åˆ°æ•°æ®åº“
            competitor_id = save_competitor_to_db(details)
            # è§¦å‘ç¿»è¯‘
            print("è§¦å‘ç¿»è¯‘ç«å“ä¿¡æ¯...")
            translate_competitor(competitor_id)
        else:
            print("âŒ æŠ“å–è¯¦æƒ…å¤±è´¥")
            return {"success": False, "message": "æŠ“å–è´¦å·è¯¦æƒ…å¤±è´¥"}
    else:
        print("ç«å“å·²å­˜åœ¨ï¼Œè·³è¿‡è¯¦æƒ…æŠ“å–")
    
    # æŠ“å–å¸–å­
    posts = scrape_posts(username, post_count, scrape_type)
    if posts:
        # ä¿å­˜åˆ°æ•°æ®åº“
        saved_count = save_posts_to_db(posts, username)
        # å·²åœ¨ä¿å­˜åæŒ‰æ¡ç¿»è¯‘ï¼Œè¿™é‡Œä¸å†æŒ‰ç”¨æˆ·åè§¦å‘æ‰¹é‡ç¿»è¯‘
        
        return {
            "success": True,
            "message": f"æˆåŠŸæŠ“å–å¹¶ä¿å­˜ {saved_count} æ¡å¸–å­",
            "post_count": saved_count
        }
    else:
        return {"success": False, "message": "æœªæŠ“å–åˆ°å¸–å­æ•°æ®"}

if __name__ == "__main__":
    # æµ‹è¯•
    result = scrape_competitor_data("camblyk", 2)
    print(f"\næœ€ç»ˆç»“æœ: {result}")

